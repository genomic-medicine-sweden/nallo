#!/usr/bin/env python3
"""Generate Gens coverage and BAF data files."""

from __future__ import annotations

import argparse
import gzip
import os
import re
import shutil
import statistics
import subprocess
import sys
from pathlib import Path
from typing import Optional, TextIO

COV_WINDOW_SIZES = [100000, 25000, 5000, 1000, 100]
BAF_SKIP_N = [160, 40, 10, 4, 1]
PREFIXES = ["o", "a", "b", "c", "d"]

joined_prefixes = ", ".join(PREFIXES)
DESCRIPTION = f"""
Generate Gens BAF and coverage data.

BAF: Given a set of predefined coordinates (i.e. common variants in Gnomad). Look through a gVCF. For SNVs in those positions, check the alternative allele frequency. Zoom levels are generated by subsampling the selected variants at the following frequencies: {", ".join([str(n) for n in BAF_SKIP_N])} (i.e. displaying 1 / X variants for that zoom level).

Coverage: Given a per-range coverage file. Given certain window sizes, calculate the average coverage within  these larger ranges. Zoom levels are set to the following cov windows: {", ".join([str(n) for n in COV_WINDOW_SIZES])}.

Both yields bed files with different levels of resolutions, distinguished with prefixes in the output ({joined_prefixes}).
"""

VERSION = "1.1.2"

CHR_ORDER = [
    "1",
    "2",
    "3",
    "4",
    "5",
    "6",
    "7",
    "8",
    "9",
    "10",
    "11",
    "12",
    "13",
    "14",
    "15",
    "16",
    "17",
    "18",
    "19",
    "20",
    "21",
    "22",
    "X",
    "Y",
    "MT",
]
CHR_ORDER_MAP = {c: i for i, c in enumerate(CHR_ORDER)}


def main(
    label: str,
    coverage: Path,
    gvcf: Path,
    baf_positions: Path,
    out_dir: Path,
    bigwig: bool,
    baf_min_depth: int,
    bgzip_tabix_output: bool,
    threads: int,
) -> None:

    out_dir.mkdir(parents=True, exist_ok=True)

    cov_output = out_dir / f"{label}.cov.bed"
    baf_output = out_dir / f"{label}.baf.bed"

    print("Calculating coverage data", file=sys.stderr)
    with open(cov_output, "w", encoding="utf-8") as covout:
        for win_size, prefix in zip(COV_WINDOW_SIZES, PREFIXES):
            generate_cov_bed(coverage, win_size, prefix, covout)

    print("Calculating BAFs from gvcf...", file=sys.stderr)
    tmp_baf = out_dir / f"{label}.baf.tmp"
    with open(tmp_baf, "w", encoding="utf-8") as tmpout:
        parse_gvcfvaf(gvcf, baf_positions, tmpout, baf_min_depth)

    with open(baf_output, "w", encoding="utf-8") as bafout:
        for skip_n, prefix in zip(BAF_SKIP_N, PREFIXES):
            print(f"Outputting BAF {prefix}...", file=sys.stderr)
            generate_baf_bed(str(tmp_baf), skip_n, prefix, bafout)

    if bigwig:
        cov_sizes = out_dir / f"{label}.cov.sizes"
        baf_sizes = out_dir / f"{label}.baf.sizes"
        cov_bw_output = out_dir / f"{label}.cov.bw"
        baf_bw_output = out_dir / f"{label}.baf.bw"
        print("Generating size files", file=sys.stderr)
        write_chrom_sizes(cov_output, cov_sizes)
        write_chrom_sizes(baf_output, baf_sizes)
        print("Generating cov bigwig", file=sys.stderr)
        gens_bed_to_bigwig(cov_output, cov_sizes, cov_bw_output)
        print("Generating baf bigwig", file=sys.stderr)
        gens_bed_to_bigwig(baf_output, baf_sizes, baf_bw_output)

    if bgzip_tabix_output:

        bgzip_present = shutil.which("bgzip")
        tabix_present = shutil.which("tabix")
        if not (bgzip_present and tabix_present):
            print(
                f"Cannot bgzip and tabix output as commands are not present in path. bgzip present: {bgzip_present}, tabix present: {tabix_present}",
                file=sys.stderr
            )
            sys.exit(1)

        print("Compressing bed files", file=sys.stderr)
        subprocess.run(["bgzip", "-f", f"-@{threads}", str(baf_output)], check=True)
        subprocess.run(
            ["tabix", "-f", "-p", "bed", str(baf_output) + ".gz"], check=True
        )
        subprocess.run(["bgzip", "-f", f"-@{threads}", str(cov_output)], check=True)
        subprocess.run(
            ["tabix", "-f", "-p", "bed", str(cov_output) + ".gz"], check=True
        )

    os.unlink(tmp_baf)


def generate_baf_bed(fn: str, skip: int, prefix: str, out_fh: TextIO) -> None:
    """Write a downsampled BAF bed file."""
    with open(fn, "r", encoding="utf-8") as fh:
        for i, line in enumerate(fh):
            if i % skip == 0:
                parts = line.rstrip().split("\t")
                if len(parts) != 3:
                    continue
                raw_chrom, pos, val = parts
                chrom = normalize_chr(raw_chrom)
                out_fh.write(f"{prefix}_{chrom}\t{int(pos) - 1}\t{pos}\t{val}\n")


def generate_cov_bed(
    cov_file: Path, win_size: int, prefix: str, out_fh: TextIO
) -> None:
    """Convert GATK standardized coverage to Gens bed format."""
    active_region = None
    force_end = False
    reg_ratios: list[float] = []

    with open(cov_file, "r", encoding="utf-8") as fh:
        for line in fh:
            if line.startswith("@") or line.startswith("CONTIG"):
                continue

            raw_chrom, start_str, end_str, ratio_str = line.rstrip().split("\t")
            chrom = normalize_chr(raw_chrom)
            curr = Region(chrom, int(start_str), int(end_str))
            orig_end = curr.end
            curr_ratio = float(ratio_str)

            if not active_region:
                active_region = Region(curr.chrom, curr.start, curr.end)

            # Check if still within the target window size
            if (
                chrom == active_region.chrom
                and curr.start - active_region.end < win_size
            ):
                reg_ratios.append(curr_ratio)
                active_region.end = curr.end
            else:
                # If not, then finish the current window
                force_end = True
                curr.end = active_region.end

            curr_window_size = curr.end - active_region.start + 1
            if curr_window_size >= win_size or force_end:
                mid_point = active_region.start + (curr.end - active_region.start) // 2
                out_fh.write(
                    f"{prefix}_{active_region.chrom}\t{mid_point - 1}\t{mid_point}\t{statistics.mean(reg_ratios)}\n"
                )
                active_region = None
                reg_ratios = []

            if force_end:
                active_region = Region(chrom, curr.start, orig_end)
                reg_ratios.append(curr_ratio)
                force_end = False


def write_chrom_sizes(cov_bed_file: Path, out_path: Path) -> None:
    chrom_sizes: dict[str, int] = {}
    chrom_order: list[str] = []
    with open(cov_bed_file, "r", encoding="utf-8") as cov_in_fh:
        for line in cov_in_fh:
            line = line.rstrip()

            if not line.startswith("d_"):
                continue

            zoom_chrom, start, end_str, val = line.split("\t")
            chrom = zoom_chrom.split("_")[1]
            end = int(end_str)
            if chrom not in chrom_sizes:
                chrom_sizes[chrom] = end
                chrom_order.append(chrom)
            elif end > chrom_sizes[chrom]:
                chrom_sizes[chrom] = end

    with open(out_path, "w", encoding="utf-8") as out_fh:
        for zoom_chrom in chrom_order:
            print(f"{zoom_chrom}\t{chrom_sizes[zoom_chrom]}", file=out_fh)


def gens_bed_to_bigwig(bed_file: Path, sizes_path: Path, bw_file: Path) -> None:

    d_only_bed = str(bed_file) + ".d_only"

    with open(bed_file, "r", encoding="utf-8") as bed_in_fh, open(
        d_only_bed, "w"
    ) as tmp_cov_bed:
        for line in bed_in_fh:
            line = line.rstrip()

            if not line.startswith("d_"):
                continue

            zoom_chrom, start, end_str, val = line.split("\t")
            chrom = zoom_chrom.split("_")[1]

            print(f"{chrom}\t{start}\t{end_str}\t{val}", file=tmp_cov_bed)

    if not shutil.which("bedGraphToBigWig"):
        print("Did not find bedGraphToBigWig in PATH, required to generate BigWig files", file=sys.stderr)
        sys.exit(1)

    subprocess.run(
        [
            "bedGraphToBigWig",
            str(d_only_bed),
            str(sizes_path),
            str(bw_file),
        ],
        check=True,
    )

    os.unlink(sizes_path)
    os.unlink(d_only_bed)


def parse_gvcfvaf(
    gvcf_file: Path, baf_positions_file: Path, out_fh: TextIO, depth_threshold: int
) -> None:
    """
    Calculate BAF frequencies for provided gnomad file positions
    Write position and BAF frequencies to file

    Considerations:
    - Skip indels
    - If no alt-allele depth (AD) assigned (i.e. no call), set frequency 0
    - If having AD reads but less than threshold, skip
    """

    baf_positions = set()
    with open(baf_positions_file, "r", encoding="utf-8") as baf_positions_fh:
        for line in baf_positions_fh:
            line = line.rstrip()
            chrom_raw, pos = line.split("\t")
            chrom = normalize_chr(chrom_raw)
            pos_key = f"{chrom}_{pos}"
            baf_positions.add(pos_key)

    with gzip.open(gvcf_file, "rt", encoding="utf-8") as gvcf_fh:

        gvcf_count = 0
        match_count = 0

        for gvcf_line in gvcf_fh:
            if gvcf_line.startswith("#"):
                continue

            gvcf_count += 1
            gvcf_pos: Region = gvcf_region(gvcf_line)
            position_key = f"{gvcf_pos.chrom}_{gvcf_pos.start}"
            if position_key not in baf_positions:
                continue

            entry = GVCFEntry(gvcf_line)
            if len(entry.ref) > 1:
                continue

            if "AD" not in entry.sample_entries:
                baf_freq = 0
            elif not entry.pass_depth_filter(depth_threshold):
                continue
            else:
                parsed_baf = entry.parse_b_allele_freq()
                if parsed_baf is None:
                    continue
                baf_freq = parsed_baf

            print(f"{gvcf_pos.chrom}\t{gvcf_pos.start}\t{baf_freq}", file=out_fh)
            match_count += 1

        skipped = gvcf_count - match_count
        print(f"{skipped} variants skipped!", file=sys.stderr)


def gvcf_region(line: str) -> Region:
    """Return END from info column if present. Else, return the start position."""
    cols = line.rstrip().split("\t")
    chrom = normalize_chr(cols[0])
    pos = int(cols[1])
    info = cols[7]
    info_end_match = re.search(r"(?:^|;)END=(.*?)(?:;|$)", info)
    end = int(info_end_match.group(1)) if info_end_match else pos
    return Region(chrom, pos, end)


class Region:
    def __init__(self, chr: str, start: int, end: int):
        self.chrom = chr
        self.start = start
        self.end = end


class GVCFEntry:
    def __init__(self, line: str):
        cols = line.split("\t")

        self.chrom = normalize_chr(cols[0])
        self.start = int(cols[1])
        self.ref = cols[3]
        self.alt_alleles = cols[4].split(",")
        self.info_str = cols[7]
        sample_keys = cols[8].split(":")
        sample_vals = cols[9].split(":")
        self.sample_entries = dict(zip(sample_keys, sample_vals))

    def pass_depth_filter(self, depth_filter: int) -> bool:
        depth = self.sample_entries.get("DP")
        if not depth:
            return False
        if int(depth) >= depth_filter:
            return True
        else:
            return False

    def parse_b_allele_freq(self) -> Optional[float]:
        """
        If the alt allele is non-SNV (i.e. several inserted bases), return None
        Otherwise return alt allele count / allele depth
        Returns None for variants without genotype call (./.)
        """

        gt = self.sample_entries["GT"]
        if "." in gt:
            return None
        _ref_str, alt_str = gt.replace("|", "/").split("/")
        alt = int(alt_str)

        allele_depths = [int(d) for d in self.sample_entries["AD"].split(",")]
        if alt != 0:
            if alt > len(self.alt_alleles):
                return None
            alt_allele_length = len(self.alt_alleles[alt - 1])
            if alt_allele_length > 1:
                return None
            alt_count = allele_depths[alt]
        else:
            alt_count = max(allele_depths[1:])

        dp = int(self.sample_entries["DP"])
        b_allele_freq = alt_count / dp
        return b_allele_freq

    def __str__(self) -> str:
        alt_alleles = ",".join(self.alt_alleles)
        return f"{self.chrom} {self.start} {self.ref} {alt_alleles}"


def normalize_chr(chrom: str) -> str:
    """Return chromosome name without 'chr' and with MT normalized"""

    if chrom.lower().startswith("chr"):
        chrom = chrom[3:]

    if chrom.lower() in {"m", "mt"}:
        return "MT"

    return chrom


def parse_arguments():
    parser = argparse.ArgumentParser(
        description=DESCRIPTION, formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument("-v", "--version", action="version", version=VERSION)

    parser.add_argument("--label", help="Output label", required=True)
    parser.add_argument(
        "--coverage",
        help="Standardized coverage, typically calculated using GATK's CollectReadCounts and DenoiseReadCounts",
        required=True,
        type=Path,
    )
    parser.add_argument(
        "--gvcf",
        help="gVCF file for calculating B-allele frequencies",
        required=True,
        type=Path,
    )
    parser.add_argument(
        "--baf_positions",
        help="Two column tsv file SNP positions for which to calculate BAFs. An example file with sites > 0.05 in Gnomad can be downloaded from here: https://github.com/SMD-Bioinformatics-Lund/gens/releases/download/v4.3.0/gnomad_hg38.0.05.txt.gz",
        required=True,
        type=Path,
    )
    parser.add_argument(
        "--baf_min_depth",
        help="Minimum depth of variant in gVCF to be included in BAF output",
        type=int,
        default=10,
    )
    parser.add_argument(
        "--threads",
        help="Number of threads to use when bgzipping output",
        type=int,
        default=10,
    )
    parser.add_argument(
        "--bgzip_tabix_output",
        help="BGZip and tabix index outputs (requires bgzip and tabix to be present in PATH)",
        action="store_true",
    )

    parser.add_argument(
        "--bigwig",
        help="Generate additional bigwigs for coverage and baf (requires bedGraphToBigWig in PATH)",
        action="store_true",
    )

    parser.add_argument("--outdir", help="Output dir", required=True, type=Path)
    args = parser.parse_args()
    return args


if __name__ == "__main__":
    args = parse_arguments()

    main(
        args.label,
        args.coverage,
        args.gvcf,
        args.baf_positions,
        args.outdir,
        args.bigwig,
        args.baf_min_depth,
        args.bgzip_tabix_output,
        args.threads,
    )
