nextflow_workflow {

    name "Test Workflow CALL_SVS"
    script "../main.nf"
    config "./nextflow.config"
    workflow "CALL_SVS"

    setup {
        run("GUNZIP") {
            script "../../../../modules/nf-core/gunzip/main.nf"
            process {
                """
                input[0] = [
                    [ id:'test' ],
                    file(params.pipelines_testdata_base_path + 'reference/hg38.test.fa.gz', checkIfExists: true)
                ]
                """
            }

        }
        run("SAMTOOLS_FAIDX") {
            script "../../../../modules/nf-core/samtools/faidx/main.nf"
            process {
                """
                input[0] = GUNZIP.out.gunzip
                input[1] = [[],[]]
                input[2] = false
                """
            }
        }

        run("MINIMAP2_ALIGN") {
            script "../../../../modules/nf-core/minimap2/align/main.nf"
            process {
                """
                input[0] = Channel.of(
                    [
                        [ id:'test_1', single_end:false, family_id: 'family', sex: 1 ], // meta map
                        file(params.pipelines_testdata_base_path + 'testdata/HG002_PacBio_Revio.bam', checkIfExists: true)
                    ],
                    [
                        [ id:'test_2', single_end:false, family_id: 'family', sex: 1 ], // meta map
                        file(params.pipelines_testdata_base_path + 'testdata/HG003_PacBio_Revio.bam', checkIfExists: true)
                    ]
                )
                input[1] = GUNZIP.out.gunzip
                input[2] = true
                input[3] = 'bai'
                input[4] = false
                input[5] = false
                """
            }
        }
        run("DEEPVARIANT_RUNDEEPVARIANT") {
            script "../../../../modules/nf-core/deepvariant/rundeepvariant/main.nf"
            process {
                """
                input[0] = MINIMAP2_ALIGN.out.bam
                    .join(MINIMAP2_ALIGN.out.index)
                    .map { meta, bam, bai -> [ meta, bam, bai, file(params.pipelines_testdata_base_path + 'reference/test_data.bed', checkIfExists: true) ] }
                input[1] = GUNZIP.out.gunzip
                input[2] = SAMTOOLS_FAIDX.out.fai
                input[3] = [[],[]]
                input[4] = [[],[]]
                """
            }
        }

    }

    test("1 sample, 1 family - sniffles") {

        when {
            workflow {
                """
                input[0] = Channel.of([
                    [ id:'test', single_end:false, family_id: 'family', sex: 1 ], // meta map
                    file(params.pipelines_testdata_base_path + 'testdata/HG002_PacBio_Revio.bam', checkIfExists: true),
                    file(params.pipelines_testdata_base_path + 'testdata/HG002_PacBio_Revio.bam.bai', checkIfExists: true)
                ])
                input[1] = [[],[]]
                input[2] = [[],[]]
                input[3] = GUNZIP.out.gunzip
                input[4] = [[],[]]
                input[5] = [[],[]]
                input[6] = [[],[]]
                input[7] = ['sniffles']
                input[8] = ['sniffles']
                input[9] = ['sniffles']
                input[10] = [[],[]]
                input[11] = false
                input[12] = false
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success },
                { assert workflow.out.family_tbi.get(0).get(1).endsWith("tbi") },
                { assert workflow.out.family_caller_tbi.get(0).get(1).endsWith("tbi") },
                { assert snapshot(
                    // nft-vcf can't parse VCFv4.4: https://github.com/seppinho/nft-vcf/issues/14
                    workflow.out.family_caller_vcf
                        .findAll { meta, vcf -> meta.sv_caller == 'sawfish' }
                        .collect { meta, vcf -> [ 'family_caller_vcf (sawfish):', meta, file(vcf).name ] },
                    workflow.out.family_caller_vcf
                        .findAll { meta, vcf -> meta.sv_caller != 'sawfish' }
                        .collect { meta, vcf -> [ 'family_caller_vcf (not sawfish):', meta, file(vcf).name, path(vcf).vcf.summary, path(vcf).vcf.variantsMD5 ] },
                    workflow.out.family_vcf
                        .collect { meta, vcf -> [ 'family_vcf:', meta, file(vcf).name, path(vcf).vcf.summary, path(vcf).vcf.variantsMD5 ]
                    },
                    workflow.out.versions,
                ).match() }
            )
        }
    }

    test("1 sample, 1 family - sawfish") {

        when {
            workflow {
                """
                input[0] = MINIMAP2_ALIGN.out.bam
                    .join(MINIMAP2_ALIGN.out.index)
                    .filter { meta, bam, bai -> meta.id == 'test_1' }
                input[1] = Channel.of([
                    [ id:'trf' ],
                    file('https://github.com/fritzsedlazeck/Sniffles/raw/master/annotations/human_GRCh38_no_alt_analysis_set.trf.bed', checkIfExists: true)
                ]).collect()
                input[2] = DEEPVARIANT_RUNDEEPVARIANT.out.vcf
                    .filter { meta, vcf -> meta.id == 'test_1' }
                input[3] = GUNZIP.out.gunzip
                input[4] = Channel.of([
                    [ id: 'xy_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/expected_cn.hg38.XY.bed', checkIfExists: true)
                ]).collect()
                input[5] = Channel.of([
                    [ id: 'xx_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/expected_cn.hg38.XX.bed', checkIfExists: true)
                ]).collect()
                input[6] = Channel.of([
                    [ id: 'exclude_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/cnv.excluded_regions.hg38.bed.gz', checkIfExists: true)
                ]).collect()
                input[7] = ['sawfish']
                input[8] = ['sawfish']
                input[9] = ['sawfish']
                input[10] = Channel.of('chr16\t160752\t160753')
                    .collectFile(name: "one_variant.bed")
                    .map { file ->
                        [ [ id: 'one_variant' ], file ]
                    }.collect()
                input[11] = false
                input[12] = false
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success },
                { assert workflow.out.family_tbi.get(0).get(1).endsWith("tbi") },
                { assert workflow.out.family_caller_tbi.get(0).get(1).endsWith("tbi") },
                { assert snapshot(
                    // nft-vcf can't parse VCFv4.4: https://github.com/seppinho/nft-vcf/issues/14
                    workflow.out.family_caller_vcf
                        .findAll { meta, vcf -> meta.sv_caller == 'sawfish' }
                        .collect { meta, vcf -> [ 'family_caller_vcf (sawfish):', meta, file(vcf).name ] },
                    workflow.out.family_caller_vcf
                        .findAll { meta, vcf -> meta.sv_caller != 'sawfish' }
                        .collect { meta, vcf -> [ 'family_caller_vcf (not sawfish):', meta, file(vcf).name, path(vcf).vcf.summary, path(vcf).vcf.variantsMD5 ] },
                    workflow.out.family_vcf
                        .collect { meta, vcf -> [ 'family_vcf:', meta, file(vcf).name, path(vcf).vcf.summary, path(vcf).vcf.variantsMD5 ]
                    },
                    workflow.out.versions,
                ).match() }
            )
        }

    }

    test("1 sample, 1 family - sawfish, force_sawfish_joint_call_single_samples true") {

        when {
            workflow {
                """
                input[0] = MINIMAP2_ALIGN.out.bam
                    .join(MINIMAP2_ALIGN.out.index)
                    .filter { meta, bam, bai -> meta.id == 'test_1' }
                input[1] = Channel.of([
                    [ id:'trf' ],
                    file('https://github.com/fritzsedlazeck/Sniffles/raw/master/annotations/human_GRCh38_no_alt_analysis_set.trf.bed', checkIfExists: true)
                ]).collect()
                input[2] = DEEPVARIANT_RUNDEEPVARIANT.out.vcf
                    .filter { meta, vcf -> meta.id == 'test_1' }
                input[3] = GUNZIP.out.gunzip
                input[4] = Channel.of([
                    [ id: 'xy_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/expected_cn.hg38.XY.bed', checkIfExists: true)
                ]).collect()
                input[5] = Channel.of([
                    [ id: 'xx_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/expected_cn.hg38.XX.bed', checkIfExists: true)
                ]).collect()
                input[6] = Channel.of([
                    [ id: 'exclude_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/cnv.excluded_regions.hg38.bed.gz', checkIfExists: true)
                ]).collect()
                input[7] = ['sawfish']
                input[8] = ['sawfish']
                input[9] = ['sawfish']
                input[10] = Channel.of('chr16\t160752\t160753')
                    .collectFile(name: "one_variant.bed")
                    .map { file ->
                        [ [ id: 'one_variant' ], file ]
                    }.collect()
                input[11] = false
                input[12] = true
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success },
                { assert workflow.out.family_tbi.get(0).get(1).endsWith("tbi") },
                { assert workflow.out.family_caller_tbi.get(0).get(1).endsWith("tbi") },
                { assert snapshot(
                    // nft-vcf can't parse VCFv4.4: https://github.com/seppinho/nft-vcf/issues/14
                    workflow.out.family_caller_vcf
                        .findAll { meta, vcf -> meta.sv_caller == 'sawfish' }
                        .collect { meta, vcf -> [ 'family_caller_vcf (sawfish):', meta, file(vcf).name ] },
                    workflow.out.family_caller_vcf
                        .findAll { meta, vcf -> meta.sv_caller != 'sawfish' }
                        .collect { meta, vcf -> [ 'family_caller_vcf (not sawfish):', meta, file(vcf).name, path(vcf).vcf.summary, path(vcf).vcf.variantsMD5 ] },
                    workflow.out.family_vcf
                        .collect { meta, vcf -> [ 'family_vcf:', meta, file(vcf).name, path(vcf).vcf.summary, path(vcf).vcf.variantsMD5 ]
                    },
                    workflow.out.versions,
                ).match() }
            )
        }

    }

    test("2 samples, 1 family - sniffes,severus,hificnv,sawfish with trf bed") {

        when {
            workflow {
                """
                input[0] = MINIMAP2_ALIGN.out.bam
                    .join(MINIMAP2_ALIGN.out.index)
                input[1] = Channel.of([
                    [ id:'trf' ],
                    file('https://github.com/fritzsedlazeck/Sniffles/raw/master/annotations/human_GRCh38_no_alt_analysis_set.trf.bed', checkIfExists: true)
                ]).collect()
                input[2] = DEEPVARIANT_RUNDEEPVARIANT.out.vcf
                input[3] = GUNZIP.out.gunzip
                input[4] = Channel.of([
                    [ id: 'xy_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/expected_cn.hg38.XY.bed', checkIfExists: true)
                ]).collect()
                input[5] = Channel.of([
                    [ id: 'xx_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/expected_cn.hg38.XX.bed', checkIfExists: true)
                ]).collect()
                input[6] = Channel.of([
                    [ id: 'exclude_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/cnv.excluded_regions.hg38.bed.gz', checkIfExists: true)
                ]).collect()
                input[7] = ['sniffles', 'hificnv', 'severus', 'sawfish']
                input[8] = ['sniffles', 'hificnv', 'severus', 'sawfish']
                input[9] = ['sniffles', 'severus', 'hificnv', 'sawfish']
                input[10] = [[],[]]
                input[11] = false
                input[12] = false
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success },
                { assert workflow.out.family_tbi.get(0).get(1).endsWith("tbi") },
                { assert workflow.out.family_caller_tbi.get(0).get(1).endsWith("tbi") },
                { assert snapshot(
                    // nft-vcf can't parse VCFv4.4: https://github.com/seppinho/nft-vcf/issues/14
                    workflow.out.family_caller_vcf
                        .findAll { meta, vcf -> meta.sv_caller == 'sawfish' }
                        .collect { meta, vcf -> [ 'family_caller_vcf (sawfish):', meta, file(vcf).name ] },
                    workflow.out.family_caller_vcf
                        .findAll { meta, vcf -> meta.sv_caller != 'sawfish' }
                        .collect { meta, vcf -> [ 'family_caller_vcf (not sawfish):', meta, file(vcf).name, path(vcf).vcf.summary, path(vcf).vcf.variantsMD5 ] },
                    // Sawfish reorders samples sometimes, so we can't have a stable MD5 here
                    workflow.out.family_vcf
                        .collect { meta, vcf -> [ 'family_vcf:', meta, file(vcf).name, path(vcf).vcf.summary ]
                    },
                    workflow.out.versions,
                ).match() }
            )
        }

    }

    test("2 samples, 1 family - merge sniffes,hificnv,severus,sawfish with trf bed, run all callers and filter") {

        when {
            workflow {
                """
                input[0] = MINIMAP2_ALIGN.out.bam
                    .join(MINIMAP2_ALIGN.out.index)
                input[1] = Channel.of([
                    [ id:'trf' ],
                    file('https://github.com/fritzsedlazeck/Sniffles/raw/master/annotations/human_GRCh38_no_alt_analysis_set.trf.bed', checkIfExists: true)
                ]).collect()
                input[2] = DEEPVARIANT_RUNDEEPVARIANT.out.vcf
                input[3] = GUNZIP.out.gunzip
                input[4] = Channel.of([
                    [ id: 'xy_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/expected_cn.hg38.XY.bed', checkIfExists: true)
                ]).collect()
                input[5] = Channel.of([
                    [ id: 'xx_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/expected_cn.hg38.XX.bed', checkIfExists: true)
                ]).collect()
                input[6] = Channel.of([
                    [ id: 'exclude_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/cnv.excluded_regions.hg38.bed.gz', checkIfExists: true)
                ]).collect()
                input[7] = ['sniffles', 'severus', 'hificnv', 'sawfish']
                input[8] = ['sniffles', 'severus', 'hificnv', 'sawfish']
                input[9] = ['sniffles', 'severus', 'hificnv', 'sawfish']
                input[10] = Channel.of('chr16\t160752\t160753')
                    .collectFile(name: "one_variant.bed")
                    .map { file ->
                        [ [ id: 'one_variant' ], file ]
                    }.collect()
                input[11] = true
                input[12] = false
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success },
                { assert workflow.out.family_tbi.get(0).get(1).endsWith("tbi") },
                { assert workflow.out.family_caller_tbi.get(0).get(1).endsWith("tbi") },
                { assert snapshot(
                    // nft-vcf can't parse VCFv4.4: https://github.com/seppinho/nft-vcf/issues/14
                    workflow.out.family_caller_vcf
                        .findAll { meta, vcf -> meta.sv_caller == 'sawfish' }
                        .collect { meta, vcf -> [ 'family_caller_vcf (sawfish):', meta, file(vcf).name ] },
                    workflow.out.family_caller_vcf
                        .findAll { meta, vcf -> meta.sv_caller != 'sawfish' }
                        .collect { meta, vcf -> [ 'family_caller_vcf (not sawfish):', meta, file(vcf).name, path(vcf).vcf.summary, path(vcf).vcf.variantsMD5 ] },
                    // Sawfish reorders samples sometimes, so we can't have a stable MD5 here
                    workflow.out.family_vcf
                        .collect { meta, vcf -> [ 'family_vcf:', meta, file(vcf).name, path(vcf).vcf.summary ]
                    },
                    workflow.out.versions,
                ).match() }
            )
        }
    }

    test("2 samples, 1 family - merge sniffes,hificnv,severus,sawfish with trf bed, run all callers and filter, force sawfish single sample joint-call") {

        when {
            workflow {
                """
                input[0] = MINIMAP2_ALIGN.out.bam
                    .join(MINIMAP2_ALIGN.out.index)
                input[1] = Channel.of([
                    [ id:'trf' ],
                    file('https://github.com/fritzsedlazeck/Sniffles/raw/master/annotations/human_GRCh38_no_alt_analysis_set.trf.bed', checkIfExists: true)
                ]).collect()
                input[2] = DEEPVARIANT_RUNDEEPVARIANT.out.vcf
                input[3] = GUNZIP.out.gunzip
                input[4] = Channel.of([
                    [ id: 'xy_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/expected_cn.hg38.XY.bed', checkIfExists: true)
                ]).collect()
                input[5] = Channel.of([
                    [ id: 'xx_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/expected_cn.hg38.XX.bed', checkIfExists: true)
                ]).collect()
                input[6] = Channel.of([
                    [ id: 'exclude_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/cnv.excluded_regions.hg38.bed.gz', checkIfExists: true)
                ]).collect()
                input[7] = ['sniffles', 'severus', 'hificnv', 'sawfish']
                input[8] = ['sniffles', 'severus', 'hificnv', 'sawfish']
                input[9] = ['sniffles', 'severus', 'hificnv', 'sawfish']
                input[10] = Channel.of('chr16\t160752\t160753')
                    .collectFile(name: "one_variant.bed")
                    .map { file ->
                        [ [ id: 'one_variant' ], file ]
                    }.collect()
                input[11] = true
                input[12] = true
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success },
                { assert workflow.out.family_tbi.get(0).get(1).endsWith("tbi") },
                { assert workflow.out.family_caller_tbi.get(0).get(1).endsWith("tbi") },
                { assert snapshot(
                    // nft-vcf can't parse VCFv4.4: https://github.com/seppinho/nft-vcf/issues/14
                    workflow.out.family_caller_vcf
                        .findAll { meta, vcf -> meta.sv_caller == 'sawfish' }
                        .collect { meta, vcf -> [ 'family_caller_vcf (sawfish):', meta, file(vcf).name ] },
                    workflow.out.family_caller_vcf
                        .findAll { meta, vcf -> meta.sv_caller != 'sawfish' }
                        .collect { meta, vcf -> [ 'family_caller_vcf (not sawfish):', meta, file(vcf).name, path(vcf).vcf.summary, path(vcf).vcf.variantsMD5 ] },
                    workflow.out.family_vcf
                        .collect { meta, vcf -> [ 'family_vcf:', meta, file(vcf).name, path(vcf).vcf.summary, path(vcf).vcf.variantsMD5 ]
                    },
                    workflow.out.versions,
                ).match() }
            )
        }
    }

    test("2 samples, 1 family - sniffes,severus with trf bed, run all callers - stub") {

        options "-stub"

        when {
            workflow {
                """
                input[0] = MINIMAP2_ALIGN.out.bam
                    .join(MINIMAP2_ALIGN.out.index)
                input[1] = [
                    [ id:'trf' ],
                    file('https://github.com/fritzsedlazeck/Sniffles/raw/master/annotations/human_GRCh38_no_alt_analysis_set.trf.bed', checkIfExists: true)
                ]
                input[2] = DEEPVARIANT_RUNDEEPVARIANT.out.vcf
                input[3] = GUNZIP.out.gunzip
                input[4] = [
                    [ id: 'xy_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/expected_cn.hg38.XY.bed', checkIfExists: true)
                ]
                input[5] = [
                    [ id: 'xx_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/expected_cn.hg38.XX.bed', checkIfExists: true)
                ]
                input[6] = [
                    [ id: 'exclude_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/cnv.excluded_regions.hg38.bed.gz', checkIfExists: true)
                ]
                input[7] = ['sniffles', 'severus', 'hificnv']
                input[8] = ['sniffles', 'severus']
                input[9] = ['sniffles', 'severus']
                input[10] = [[],[]]
                input[11] = false
                input[12] = false
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success },
                { assert snapshot(workflow.out).match() }
            )
        }
    }

    test("1 sample, 1 family - sawfish, force_sawfish_joint_call_single_samples true -stub") {

        options "-stub"

        when {
            workflow {
                """
                input[0] = MINIMAP2_ALIGN.out.bam
                    .join(MINIMAP2_ALIGN.out.index)
                    .filter { meta, bam, bai -> meta.id == 'test_1' }
                input[1] = Channel.of([
                    [ id:'trf' ],
                    file('https://github.com/fritzsedlazeck/Sniffles/raw/master/annotations/human_GRCh38_no_alt_analysis_set.trf.bed', checkIfExists: true)
                ]).collect()
                input[2] = DEEPVARIANT_RUNDEEPVARIANT.out.vcf
                    .filter { meta, vcf -> meta.id == 'test_1' }
                input[3] = GUNZIP.out.gunzip
                input[4] = Channel.of([
                    [ id: 'xy_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/expected_cn.hg38.XY.bed', checkIfExists: true)
                ]).collect()
                input[5] = Channel.of([
                    [ id: 'xx_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/expected_cn.hg38.XX.bed', checkIfExists: true)
                ]).collect()
                input[6] = Channel.of([
                    [ id: 'exclude_bed' ],
                    file(params.pipelines_testdata_base_path + 'reference/cnv.excluded_regions.hg38.bed.gz', checkIfExists: true)
                ]).collect()
                input[7] = ['sawfish']
                input[8] = ['sawfish']
                input[9] = ['sawfish']
                input[10] = Channel.of('chr16\t160752\t160753')
                    .collectFile(name: "one_variant.bed")
                    .map { file ->
                        [ [ id: 'one_variant' ], file ]
                    }.collect()
                input[11] = false
                input[12] = false
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success },
                { assert snapshot(workflow.out).match() }
            )
        }
    }
}
