nextflow_workflow {

    name "Test Workflow ANNOTATE_SNVS"
    script "../main.nf"
    workflow "ANNOTATE_SNVS"
    config "./nextflow.config"

    setup {
        run("GUNZIP") {
            script "../../../../modules/nf-core/gunzip/main.nf"
            process {
                """
                input[0] = [
                    [ id:'hg38' ],
                    file(params.pipelines_testdata_base_path + 'reference/hg38.test.fa.gz', checkIfExists: true)
                ]
                """
            }
        }
        run("SAMTOOLS_FAIDX") {
            script "../../../../modules/nf-core/samtools/faidx/main.nf"
            process {
                """
                input[0] = GUNZIP.out.gunzip
                input[1] = [[],[]]
                input[2] = false
                """
            }
        }
        run("UNTAR") {
            script "../../../../modules/nf-core/untar/main.nf"
            process {
                """
                input[0] = [
                    [ id: 'vep_cache' ],
                    file(params.pipelines_testdata_base_path + 'reference/vep_cache_test_data.tar.gz', checkIfExists:true)
                ]
                """
            }
        }

    }

    test("bcf, db, vep_cache, '110'") {

        when {
            workflow {
                """
                input[0] = Channel.of([
                    [ id: 'test' ],
                    file(params.pipelines_testdata_base_path + 'testdata/NIST_deepvariant_norm.vcf.gz', checkIfExists: true)
                ])
                input[1] = [
                    file(params.pipelines_testdata_base_path + 'reference/cadd.v1.6.hg38.test_data.zip', checkIfExists: true)
                ]
                input[2] = GUNZIP.out.gunzip
                input[3] = SAMTOOLS_FAIDX.out.fai
                input[4] = UNTAR.out.untar.map { meta, cache -> cache }
                input[5] = Channel.value('110')
                input[6] = Channel.of([
                    file(params.pipelines_testdata_base_path + 'reference/vep_plugin_files.csv', checkIfExists: true)
                ]).splitCsv(header:true).map { row -> row.vep_files }.collect()
                input[7] = false
                input[8] = true
                input[9] = Channel.value([])
                input[10] = null
                input[11] = null
                input[12] = false
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success },
                { assert snapshot(
                    workflow.out.versions,
                    file(workflow.out.tbi.get(0).get(1)).name,
                    path(workflow.out.vcf.get(0).get(1)).vcf.variantsMD5,
                    path(workflow.out.vcf.get(0).get(1)).vcf.summary,
                ).match() }
            )
        }

    }

    test("bcf, db, vep_cache, '110', filter before vep") {

        when {
            workflow {
                """
                input[0] = Channel.of([
                    [ id: 'test' ],
                    file(params.pipelines_testdata_base_path + 'testdata/NIST_deepvariant_norm.vcf.gz', checkIfExists: true)
                ])
                input[1] = [
                    file(params.pipelines_testdata_base_path + 'reference/cadd.v1.6.hg38.test_data.zip', checkIfExists: true)
                ]
                input[2] = GUNZIP.out.gunzip
                input[3] = SAMTOOLS_FAIDX.out.fai
                input[4] = UNTAR.out.untar.map { meta, cache -> cache }
                input[5] = Channel.value('110')
                input[6] = Channel.of([
                    file(params.pipelines_testdata_base_path + 'reference/vep_plugin_files.csv', checkIfExists: true)
                ]).splitCsv(header:true).map { row -> row.vep_files }.collect()
                input[7] = false
                input[8] = true
                input[9] = Channel.value([])
                input[10] = null
                input[11] = null
                input[12] = true
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success },
                { assert snapshot(
                    workflow.out.versions,
                    file(workflow.out.tbi.get(0).get(1)).name,
                    path(workflow.out.vcf.get(0).get(1)).vcf.variantsMD5,
                    path(workflow.out.vcf.get(0).get(1)).vcf.summary,
                ).match() }
            )
        }

    }

    test("bcf, [], vep_cache, '110' - no echtvar annotation") {

        when {
            workflow {
                """
                input[0] = Channel.of([
                    [ id: 'test' ],
                    file(params.pipelines_testdata_base_path + 'testdata/NIST_deepvariant_norm.vcf.gz', checkIfExists: true)
                ])
                input[1] = Channel.value([])
                input[2] = GUNZIP.out.gunzip
                input[3] = SAMTOOLS_FAIDX.out.fai
                input[4] = UNTAR.out.untar.map { meta, cache -> cache }
                input[5] = Channel.value('110')
                input[6] = Channel.of([
                    file(params.pipelines_testdata_base_path + 'reference/vep_plugin_files.csv', checkIfExists: true)
                ]).splitCsv(header:true).map { row -> row.vep_files }.collect()
                input[7] = false
                input[8] = false
                input[9] = Channel.value([])
                input[10] = null
                input[11] = null
                input[12] = false
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success },
                { assert snapshot(
                    workflow.out.versions,
                    file(workflow.out.tbi.get(0).get(1)).name,
                    path(workflow.out.vcf.get(0).get(1)).vcf.variantsMD5,
                    path(workflow.out.vcf.get(0).get(1)).vcf.summary,
                ).match() }
            )
        }

    }

    test("bcf, [], vep_cache, '110' - no echtvar annotation - filter before vep") {

        when {
            workflow {
                """
                input[0] = Channel.of([
                    [ id: 'test' ],
                    file(params.pipelines_testdata_base_path + 'testdata/NIST_deepvariant_norm.vcf.gz', checkIfExists: true)
                ])
                input[1] = Channel.value([])
                input[2] = GUNZIP.out.gunzip
                input[3] = SAMTOOLS_FAIDX.out.fai
                input[4] = UNTAR.out.untar.map { meta, cache -> cache }
                input[5] = Channel.value('110')
                input[6] = Channel.of([
                    file(params.pipelines_testdata_base_path + 'reference/vep_plugin_files.csv', checkIfExists: true)
                ]).splitCsv(header:true).map { row -> row.vep_files }.collect()
                input[7] = false
                input[8] = false
                input[9] = Channel.value([])
                input[10] = null
                input[11] = null
                input[12] = true
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success },
                { assert snapshot(
                    workflow.out.versions,
                    file(workflow.out.tbi.get(0).get(1)).name,
                    path(workflow.out.vcf.get(0).get(1)).vcf.variantsMD5,
                    path(workflow.out.vcf.get(0).get(1)).vcf.summary,
                ).match() }
            )
        }

    }

    test("bcf, db, vep_cache, '110', -stub") {

        options "-stub"

        when {
            params {
            }
            workflow {
                """
                input[0] = Channel.of([
                    [ id: 'test' ],
                    file(params.pipelines_testdata_base_path + 'testdata/NIST_deepvariant_norm.vcf.gz', checkIfExists: true)
                ])
                input[1] = [
                    file(params.pipelines_testdata_base_path + 'reference/cadd.v1.6.hg38.test_data.zip', checkIfExists: true)
                ]
                input[2] = GUNZIP.out.gunzip
                input[3] = SAMTOOLS_FAIDX.out.fai
                input[4] = UNTAR.out.untar.map { meta, cache -> cache }
                input[5] = Channel.value('110')
                input[6] = Channel.of([
                    file(params.pipelines_testdata_base_path + 'reference/vep_plugin_files.csv', checkIfExists: true)
                ]).splitCsv(header:true).map { row -> row.vep_files }.collect()
                input[7] = false
                input[8] = true
                input[9] = Channel.value([])
                input[10] = null
                input[11] = null
                input[12] = false
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success },
                { assert snapshot(
                    workflow.out.versions,
                    workflow.out.tbi,
                    workflow.out.vcf
                ).match() }
            )
        }

    }

    test("bcf, db, vep_cache, '110', -stub with CADD") {

        options "-stub"

        when {
            params {
            }
            workflow {
                """
                input[0] = Channel.of([
                    [ id: 'test' ],
                    file(params.pipelines_testdata_base_path + 'testdata/NIST_deepvariant_norm.vcf.gz', checkIfExists: true)
                ])
                input[1] = [
                    file(params.pipelines_testdata_base_path + 'reference/cadd.v1.6.hg38.test_data.zip', checkIfExists: true)
                ]
                input[2] = GUNZIP.out.gunzip
                input[3] = SAMTOOLS_FAIDX.out.fai
                input[4] = UNTAR.out.untar.map { meta, cache -> cache }
                input[5] = Channel.value('110')
                input[6] = Channel.of([
                    file(params.pipelines_testdata_base_path + 'reference/vep_plugin_files.csv', checkIfExists: true)
                ]).splitCsv(header:true).map { row -> row.vep_files }.collect()
                input[7] = false
                input[8] = true
                input[9] = Channel.of([
                    [ id: 'test' ],
                    file("$projectDir/assets/cadd_to_vcf_header_-1.0-.txt", checkIfExists: true)
                ])
                input[10] = Channel.of([
                    [ id: 'test' ],
                    file("$projectDir/assets/", checkIfExists: true)
                ])
                input[11] = Channel.of([
                    [ id: 'test' ],
                    file("$projectDir/docs/", checkIfExists: true)
                ])
                input[12] = false
                """
            }
        }

        then {
            assertAll(
                { assert workflow.success },
                { assert snapshot(
                    workflow.out.versions,
                    workflow.out.tbi,
                    workflow.out.vcf
                ).match() }
            )
        }

    }

}
